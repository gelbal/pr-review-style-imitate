{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "from typing import List, Dict\n",
    "import warnings\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "\n",
    "from utils.helper import load_env\n",
    "from haystack import Pipeline\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack_integrations.components.generators.anthropic import AnthropicGenerator\n",
    "from haystack.utils import Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore notebook warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "load_env()\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root() -> str:\n",
    "    \"\"\"Get project root path consistently\"\"\"\n",
    "    current_dir = os.getcwd()\n",
    "    return os.path.abspath(os.path.join(current_dir, '..', '..')) if current_dir.endswith('notebooks') else current_dir\n",
    "\n",
    "def parse_diff_content(diff_content: str) -> List[Dict]:\n",
    "    \"\"\"Parse diff content into structured format\"\"\"\n",
    "    files = []\n",
    "    current_file = None\n",
    "    current_diff = []\n",
    "\n",
    "    for line in diff_content.split('\\n'):\n",
    "        if line.startswith('diff --git'):\n",
    "            if current_file:\n",
    "                files.append({\n",
    "                    \"filename\": current_file,\n",
    "                    \"diff\": '\\n'.join(current_diff)\n",
    "                })\n",
    "            current_file = line.split()[-1].replace('b/', '')\n",
    "            current_diff = []\n",
    "        else:\n",
    "            current_diff.append(line)\n",
    "\n",
    "    # Add the last file\n",
    "    if current_file:\n",
    "        files.append({\n",
    "            \"filename\": current_file,\n",
    "            \"diff\": '\\n'.join(current_diff)\n",
    "        })\n",
    "\n",
    "    return files\n",
    "\n",
    "def read_reviewer_data(reviewer_name: str, repo_name: str) -> List[Dict]:\n",
    "    \"\"\"Read reviewer's PR data from processed files\"\"\"\n",
    "    project_root = get_project_root()\n",
    "    enriched_prs_path = os.path.join(project_root, 'data', 'processed', repo_name, f\"{repo_name}_enriched_prs.json\")\n",
    "\n",
    "    if not os.path.exists(enriched_prs_path):\n",
    "        raise FileNotFoundError(f\"The file {enriched_prs_path} does not exist.\")\n",
    "\n",
    "    with open(enriched_prs_path, 'r', encoding='utf-8') as f:\n",
    "        all_prs = json.load(f)\n",
    "\n",
    "    # Filter PRs reviewed by the given reviewer\n",
    "    reviewer_prs = [\n",
    "        pr for pr in all_prs\n",
    "        if reviewer_name in pr.get('reviewers', [])\n",
    "    ]\n",
    "\n",
    "    # Filter out confidential PRs (either True or missing classification)\n",
    "    non_confidential_prs = [\n",
    "        pr for pr in reviewer_prs\n",
    "        if pr.get('confidentiality', {}).get('is_confidential') == False\n",
    "    ]\n",
    "\n",
    "    # Score PRs based on engagement and changes\n",
    "    scored_prs = []\n",
    "    for pr in non_confidential_prs:\n",
    "        # Count reviews and comments by this reviewer\n",
    "        review_count = sum(1 for review in pr.get('reviews', [])\n",
    "                          if review.get('user_login') == reviewer_name)\n",
    "        comment_count = sum(1 for comment in pr.get('review_comments', [])\n",
    "                          if comment.get('user_login') == reviewer_name)\n",
    "\n",
    "        # Count lines changed if diff_content exists\n",
    "        lines_changed = 0\n",
    "        if pr.get('diff_content'):\n",
    "            lines_changed = len([line for line in pr['diff_content'].split('\\n')\n",
    "                               if line.startswith('+') or line.startswith('-')])\n",
    "\n",
    "        # Calculate engagement score\n",
    "        engagement_score = (review_count * 5) + (comment_count * 2) + (lines_changed * 0.1)\n",
    "\n",
    "        scored_prs.append({\n",
    "            **pr,\n",
    "            'engagement_score': engagement_score,\n",
    "            'reviewer_login': reviewer_name  # Add reviewer info for template\n",
    "        })\n",
    "\n",
    "    # Sort by engagement score and take top N (e.g., top 100)\n",
    "    top_prs = sorted(scored_prs, key=lambda x: x['engagement_score'], reverse=True)[:100]\n",
    "\n",
    "    print(f\"Found {len(reviewer_prs)} total PRs reviewed by {reviewer_name}\")\n",
    "    print(f\"Found {len(non_confidential_prs)} non-confidential PRs\")\n",
    "    print(f\"Selected top {len(top_prs)} PRs based on engagement score\")\n",
    "\n",
    "    # Randomly select 60 PRs from the top 100\n",
    "    prs = random.sample(top_prs, min(60, len(top_prs)))\n",
    "\n",
    "    return prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Analyze the following pull request reviews by a single reviewer. Based on these reviews, create a comprehensive set of instructions for reviewing pull requests that authentically mimics the reviewer's unique style. Focus on the following aspects:\n",
    "\n",
    "1. Review Focus Areas:\n",
    "   - Code structure and organization\n",
    "   - Performance considerations\n",
    "   - Security implications\n",
    "   - Testing requirements\n",
    "   - Documentation standards\n",
    "\n",
    "2. Review Style:\n",
    "   - Level of detail in comments\n",
    "   - Tone of feedback (e.g., direct, suggestive, questioning)\n",
    "   - Balance between positive and critical feedback\n",
    "   - Use of code examples in suggestions\n",
    "\n",
    "3. Common Patterns:\n",
    "   - Recurring concerns or emphasis\n",
    "   - Preferred coding patterns\n",
    "   - Common suggestions for improvement\n",
    "   - Typical areas of scrutiny\n",
    "\n",
    "4. Technical Depth:\n",
    "   - Level of technical discussion\n",
    "   - Focus on implementation details\n",
    "   - Architectural considerations\n",
    "   - Performance optimization suggestions\n",
    "\n",
    "5. Communication Style:\n",
    "   - Comment formatting and structure\n",
    "   - Use of questions vs. direct statements\n",
    "   - References to documentation or best practices\n",
    "   - Interaction with PR authors\n",
    "\n",
    "6. Review Process:\n",
    "   - Thoroughness of review\n",
    "   - Focus on specific file types or areas\n",
    "   - Sequential vs. holistic review approach\n",
    "   - Follow-up patterns\n",
    "\n",
    "7. Best Practices Enforcement:\n",
    "   - Coding standards emphasized\n",
    "   - Testing requirements\n",
    "   - Documentation expectations\n",
    "   - Error handling preferences\n",
    "\n",
    "8. Unique Characteristics:\n",
    "   - Signature phrases or expressions\n",
    "   - Distinctive ways of providing feedback\n",
    "   - Special attention areas\n",
    "   - Personal review checklist items\n",
    "\n",
    "Here are the reviews to analyze:\n",
    "\n",
    "{% for pr in prs %}\n",
    "PR #{{ pr.pr_id }}:\n",
    "Title: {{ pr.title }}\n",
    "Body: {{ pr.body }}\n",
    "\n",
    "Reviews:\n",
    "{% for review in pr.reviews %}\n",
    "{% if review.user_login == pr.reviewer_login %}\n",
    "- {{ review.body }}\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "\n",
    "Comments:\n",
    "{% for comment in pr.review_comments %}\n",
    "{% if comment.user_login == pr.reviewer_login %}\n",
    "- {{ comment.body }}\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "\n",
    "{% endfor %}\n",
    "\n",
    "Based on these reviews, provide a detailed set of instructions for reviewing pull requests that convincingly mimics this reviewer's style. The instructions should be comprehensive enough that another reviewer could use them to provide feedback in a similar manner.\n",
    "\n",
    "Your response should be in the following format:\n",
    "\n",
    "Review Instructions for [Reviewer Name]:\n",
    "1. [First instruction]\n",
    "2. [Second instruction]\n",
    "3. [Third instruction]\n",
    "...\n",
    "\n",
    "Ensure your instructions cover all the aspects mentioned above, providing specific examples from the reviewer's comments where relevant. The goal is to capture not just the superficial elements of the review style, but also the underlying technical focus and approach to code review.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_instructions_to_disk(reviewer_name: str, repo_name: str, instruction_type: str, instructions: str):\n",
    "    \"\"\"Save reviewer instructions to disk\"\"\"\n",
    "    project_root = get_project_root()\n",
    "    instructions_dir = os.path.join(project_root, 'data', 'reviewer_instructions', repo_name)\n",
    "    os.makedirs(instructions_dir, exist_ok=True)\n",
    "\n",
    "    file_path = os.path.join(instructions_dir, f\"{reviewer_name}_{instruction_type}_instructions.txt\")\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(instructions)\n",
    "    print(f\"{instruction_type.capitalize()} instructions saved to {file_path}\")\n",
    "\n",
    "\n",
    "def load_instructions_from_disk(reviewer_name: str, repo_name: str, instruction_type: str = \"review\") -> str:\n",
    "    \"\"\"Load reviewer instructions from disk\"\"\"\n",
    "    project_root = get_project_root()\n",
    "    file_path = os.path.join(project_root, 'data', 'reviewer_instructions', repo_name,\n",
    "                            f\"{reviewer_name}_{instruction_type}_instructions.txt\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    return None\n",
    "\n",
    "def generate_reviewer_prompt(reviewer_name: str, repo_name: str, instruction_type: str = \"review\") -> str:\n",
    "    print(f\"Generating {instruction_type} prompt for reviewer: {reviewer_name}\")\n",
    "    prs = read_reviewer_data(reviewer_name, repo_name)\n",
    "\n",
    "    if not prs:\n",
    "        return f\"No PR reviews found for {reviewer_name}\"\n",
    "\n",
    "    input_dict = {\n",
    "        \"prs\": prs\n",
    "    }\n",
    "\n",
    "    prompt_builder = PromptBuilder(template=prompt_template)\n",
    "    generator = AnthropicGenerator(\n",
    "        api_key=Secret.from_env_var(\"ANTHROPIC_API_KEY\"),\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        generation_kwargs={\n",
    "            \"max_tokens\": 8192,\n",
    "            \"temperature\": 0.3\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "    pipeline.add_component(instance=generator, name=\"llm\")\n",
    "    pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "    result = pipeline.run(data=input_dict)\n",
    "    review_instructions = result[\"llm\"][\"replies\"][0]\n",
    "\n",
    "    print(f\"{instruction_type.capitalize()} instructions generated for {reviewer_name}\")\n",
    "    save_instructions_to_disk(reviewer_name, repo_name, instruction_type, review_instructions)\n",
    "    return review_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers = [\"gelbal\"]\n",
    "for reviewer_name in reviewers:\n",
    "    repo_name = \"nosara\"\n",
    "    instruction_type = \"review\"\n",
    "    instructions = generate_reviewer_prompt(reviewer_name, repo_name, instruction_type)\n",
    "    print(instructions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
