{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from typing import List, Dict, Set, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Add the project root to the Python path\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore notebook warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_root() -> str:\n",
    "    \"\"\"Get project root path consistently\"\"\"\n",
    "    current_dir = os.getcwd()\n",
    "    return os.path.abspath(os.path.join(current_dir, '..', '..')) if current_dir.endswith('notebooks') else current_dir\n",
    "\n",
    "def get_data_dir(repo_name: str, data_type: str = \"input\", user_type: Optional[str] = None) -> str:\n",
    "    \"\"\"Get data directory path with proper directory structure\n",
    "\n",
    "    Args:\n",
    "        repo_name: Name of the repository\n",
    "        data_type: Type of data (input/processed)\n",
    "        user_type: Type of user data (author/reviewer)\n",
    "\n",
    "    Returns:\n",
    "        Path to the appropriate directory\n",
    "    \"\"\"\n",
    "    project_root = get_project_root()\n",
    "\n",
    "    # Handle user-specific directories for processed data\n",
    "    if data_type == \"processed\" and user_type:\n",
    "        return os.path.join(project_root, 'data', data_type, f\"{user_type}_prs\", repo_name)\n",
    "\n",
    "    # Handle input data and other processed data\n",
    "    return os.path.join(project_root, 'data', data_type, repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(filepath: str) -> List[Dict]:\n",
    "    \"\"\"Read JSON file safely\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return []\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def read_prs_from_json(repo_name: str) -> List[Dict]:\n",
    "    \"\"\"Read PRs from the JSON file\"\"\"\n",
    "    data_dir = get_data_dir(repo_name)\n",
    "    return read_json_file(os.path.join(data_dir, \"pull_requests.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_diff_content(diff_content: str) -> List[Dict]:\n",
    "    \"\"\"Parse diff content into structured format\"\"\"\n",
    "    files = []\n",
    "    current_file = None\n",
    "    current_diff = []\n",
    "\n",
    "    for line in diff_content.split('\\n'):\n",
    "        if line.startswith('diff --git'):\n",
    "            if current_file:\n",
    "                files.append({\n",
    "                    \"filename\": current_file,\n",
    "                    \"diff\": '\\n'.join(current_diff)\n",
    "                })\n",
    "            current_file = line.split()[-1].replace('b/', '')\n",
    "            current_diff = []\n",
    "        else:\n",
    "            current_diff.append(line)\n",
    "\n",
    "    # Add the last file\n",
    "    if current_file:\n",
    "        files.append({\n",
    "            \"filename\": current_file,\n",
    "            \"diff\": '\\n'.join(current_diff)\n",
    "        })\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack.utils import Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class PRConfidentialityClassification(BaseModel):\n",
    "    is_confidential: bool = Field(description=\"Whether the PR contains confidential information\")\n",
    "    reasoning: str = Field(description=\"Explanation for the classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "from pydantic import ValidationError\n",
    "from typing import Optional\n",
    "from colorama import Fore\n",
    "from haystack import component\n",
    "\n",
    "@component\n",
    "class OutputValidator:\n",
    "    def __init__(self, pydantic_model: pydantic.BaseModel):\n",
    "        self.pydantic_model = pydantic_model\n",
    "        self.iteration_counter = 0\n",
    "\n",
    "    @component.output_types(valid_replies=List[str], invalid_replies=Optional[List[str]], error_message=Optional[str])\n",
    "    def run(self, replies: List[str]):\n",
    "        self.iteration_counter += 1\n",
    "\n",
    "        try:\n",
    "            output_dict = json.loads(replies[0])\n",
    "            # My local model sometimes returns a 'properties' wrapper. But the content adheres to the schema.\n",
    "            if 'properties' in output_dict:\n",
    "                output_dict = output_dict['properties']\n",
    "            self.pydantic_model.parse_obj(output_dict)\n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Valid JSON from LLM - No need for looping: {replies[0]}\"\n",
    "            )\n",
    "            return {\"valid_replies\": [replies[0]]}\n",
    "\n",
    "        except (ValueError, ValidationError) as e:\n",
    "            print(\n",
    "                Fore.RED\n",
    "                + f\"OutputValidator at Iteration {self.iteration_counter}: Invalid JSON from LLM - Let's try again.\\n\"\n",
    "                f\"Output from LLM:\\n {replies[0]} \\n\"\n",
    "                f\"Error from OutputValidator: {e}\"\n",
    "            )\n",
    "            return {\"invalid_replies\": replies, \"error_message\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Analyze the following Pull Request and determine if it contains any confidential or sensitive information that should not be publicly visible. Create a complete, valid JSON object with your classification and reasoning.\n",
    "\n",
    "Pull Request:\n",
    "Title: {{pr['title']}}\n",
    "Description: {{pr['body']}}\n",
    "Repository: {{pr['repository']}}\n",
    "Labels: {{pr['label_names']}}\n",
    "\n",
    "Changes:\n",
    "{% for file in files_changed %}\n",
    "File: {{file.filename}}\n",
    "```\n",
    "{{file.diff}}\n",
    "```\n",
    "{% endfor %}\n",
    "\n",
    "{% if reviews %}\n",
    "Reviews:\n",
    "{% for review in reviews %}\n",
    "- Reviewer: {{review['user_login']}}\n",
    "  Comment: {{review['body']}}\n",
    "{% endfor %}\n",
    "{% endif %}\n",
    "\n",
    "{% if review_comments %}\n",
    "Review Comments:\n",
    "{% for comment in review_comments %}\n",
    "- Commenter: {{comment['user_login']}}\n",
    "  Comment: {{comment['body']}}\n",
    "  {% if comment.get('path') %}  File: {{comment['path']}}{% endif %}\n",
    "{% endfor %}\n",
    "{% endif %}\n",
    "\n",
    "Guidelines for classification:\n",
    "1. Confidential information includes:\n",
    "   - Database credentials, API keys, or authentication tokens\n",
    "   - Internal metrics, KPIs, or business performance data\n",
    "   - Customer data or usage patterns\n",
    "   - Unreleased product features or development plans\n",
    "   - Security vulnerabilities or fixes\n",
    "\n",
    "2. Non-confidential information includes:\n",
    "   - General code changes and improvements\n",
    "   - Public documentation updates\n",
    "   - Bug fixes without security implications\n",
    "   - UI/UX improvements\n",
    "   - Performance optimizations without internal metrics\n",
    "   - Public API changes\n",
    "   - Open source dependencies updates\n",
    "   - General refactoring\n",
    "   - Test additions or updates\n",
    "   - Public feature documentation\n",
    "\n",
    "3. When in doubt, classify as confidential. Better to be cautious with potentially sensitive information.\n",
    "\n",
    "4. Consider the entire PR context:\n",
    "   - Check if title contains internal information\n",
    "   - Check for sensitive data in code changes\n",
    "   - Review any mentioned customer names or personal information\n",
    "\n",
    "Keep your response short. Follow this JSON schema for your response:\n",
    "{\n",
    "    \"is_confidential\": boolean,\n",
    "    \"reasoning\": string # maximum 2 short sentences\n",
    "}\n",
    "\n",
    "Make sure your response is a complete, valid JSON object (dict) and not a list. Ensure all opening brackets, braces, and quotes have matching closing ones.\n",
    "\n",
    "{% if invalid_replies and error_message %}\n",
    "  You already created the following output in a previous attempt: {{invalid_replies}}\n",
    "  However, this doesn't comply with the format requirements from above and triggered this Python exception: {{error_message}}\n",
    "  Correct the output and try again. Just return the corrected output without any extra explanations.\n",
    "{% endif %}\n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfidentialityClassification(BaseModel):\n",
    "    is_confidential: bool = Field(description=\"Whether the PR contains confidential information\")\n",
    "    reasoning: str = Field(description=\"Explanation for the classification\")\n",
    "\n",
    "# Custom exceptions\n",
    "class PRClassificationError(Exception):\n",
    "    \"\"\"Raised when PR classification fails\"\"\"\n",
    "    pass\n",
    "\n",
    "class FileNotFoundError(Exception):\n",
    "    \"\"\"Raised when required input files are missing\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OutputValidator with the Pydantic model\n",
    "output_validator = OutputValidator(pydantic_model=ConfidentialityClassification)\n",
    "\n",
    "generator = OllamaGenerator(model=\"qwen2.5\",\n",
    "                            url = \"http://localhost:11434\",\n",
    "                            generation_kwargs={\n",
    "                            \"num_predict\": 100,\n",
    "                            \"temperature\": 0.7,\n",
    "                            })\n",
    "\n",
    "pipeline = Pipeline(max_runs_per_component=3)\n",
    "\n",
    "# Add components to the pipeline\n",
    "pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
    "pipeline.add_component(instance=generator, name=\"llm\")\n",
    "pipeline.add_component(instance=output_validator, name=\"output_validator\")\n",
    "\n",
    "# Connect the components\n",
    "pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "pipeline.connect(\"llm\", \"output_validator\")\n",
    "pipeline.connect(\"output_validator.invalid_replies\", \"prompt_builder.invalid_replies\")\n",
    "pipeline.connect(\"output_validator.error_message\", \"prompt_builder.error_message\")\n",
    "\n",
    "pipeline.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRClassifier:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.max_retries = 3\n",
    "\n",
    "    def _validate_classification(self, data: Dict) -> bool:\n",
    "        \"\"\"Validate classification has required fields with correct types\"\"\"\n",
    "        try:\n",
    "            # Check required fields exist\n",
    "            if 'is_confidential' not in data or 'reasoning' not in data:\n",
    "                print(\"Missing required fields\")\n",
    "                return False\n",
    "\n",
    "            # Check types\n",
    "            if not isinstance(data['is_confidential'], bool):\n",
    "                print(f\"Invalid type for is_confidential: {type(data['is_confidential'])}\")\n",
    "                return False\n",
    "\n",
    "            if not isinstance(data['reasoning'], str):\n",
    "                print(f\"Invalid type for reasoning: {type(data['reasoning'])}\")\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Validation error: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def classify_pr(self, pr: Dict) -> Dict:\n",
    "        \"\"\"Classify a PR using the LLM pipeline with retries\"\"\"\n",
    "        last_error = None\n",
    "\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                files_changed = parse_diff_content(pr['diff_content'])\n",
    "                result = self.pipeline.run({\n",
    "                    \"pr\": pr,\n",
    "                    \"files_changed\": files_changed,\n",
    "                    \"reviews\": pr.get('reviews', []),\n",
    "                    \"review_comments\": pr.get('review_comments', [])\n",
    "                })\n",
    "\n",
    "                if \"output_validator\" in result and \"valid_replies\" in result[\"output_validator\"]:\n",
    "                    llm_output = result[\"output_validator\"][\"valid_replies\"][0]\n",
    "                    classification = json.loads(llm_output)\n",
    "\n",
    "                    if self._validate_classification(classification):\n",
    "                        pr['confidentiality'] = {\n",
    "                            'is_confidential': classification['is_confidential'],\n",
    "                            'reasoning': classification['reasoning'],\n",
    "                            'classified_at': datetime.now().isoformat()\n",
    "                        }\n",
    "                        return pr\n",
    "\n",
    "                print(f\"Attempt {attempt + 1}: Invalid classification format\")\n",
    "                print(f\"LLM output: {llm_output}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "\n",
    "        raise PRClassificationError(f\"Failed to classify PR {pr['id']} after {self.max_retries} attempts: {str(last_error)}\")\n",
    "\n",
    "def save_user_data(repo_name: str, user: str, user_type: str, user_data: Dict):\n",
    "    \"\"\"Save user data to the appropriate file\"\"\"\n",
    "    user_dir = get_data_dir(repo_name, \"processed\", user_type)\n",
    "    os.makedirs(user_dir, exist_ok=True)\n",
    "\n",
    "    filepath = os.path.join(user_dir, f\"{user}.json\")\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(user_data, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_confidentiality_status(repo_name: str, classifier, batch_size: int = 10):\n",
    "    \"\"\"Update confidentiality status for all PRs in a repo using classify_pr\"\"\"\n",
    "    # Load enriched PRs\n",
    "    processed_dir = get_data_dir(repo_name, \"processed\")\n",
    "    enriched_file = os.path.join(processed_dir, f\"{repo_name}_enriched_prs.json\")\n",
    "\n",
    "    with open(enriched_file, 'r') as f:\n",
    "        enriched_prs = json.load(f)\n",
    "\n",
    "    # Create lookup for existing PRs\n",
    "    pr_lookup = {pr['html_url']: pr for pr in enriched_prs}\n",
    "    print(f\"Processing {len(enriched_prs)} PRs for confidentiality check\")\n",
    "\n",
    "    # Process PRs in batches\n",
    "    current_batch = []\n",
    "    for i in range(0, len(enriched_prs), batch_size):\n",
    "        batch = enriched_prs[i:i + batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{len(enriched_prs)//batch_size + 1}\")\n",
    "\n",
    "        for pr in batch:\n",
    "            try:\n",
    "                # Skip if already classified\n",
    "                if 'confidentiality' in pr and pr['confidentiality'].get('classified_at'):\n",
    "                    print(f\"Skipping already classified PR #{pr['html_url'].split('/')[-1]}\")\n",
    "                    continue\n",
    "\n",
    "                # Use classify_pr to determine confidentiality\n",
    "                classified_pr = classifier.classify_pr(pr)\n",
    "\n",
    "                # Update lookup and add to current batch\n",
    "                pr_lookup[pr['html_url']] = classified_pr\n",
    "                current_batch.append(classified_pr)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing PR {pr['html_url']}: {e}\")\n",
    "\n",
    "        # Save after each batch, preserving all existing data\n",
    "        if current_batch:\n",
    "            print(f\"Saving batch of {len(current_batch)} newly classified PRs...\")\n",
    "            with open(enriched_file, 'w') as f:\n",
    "                json.dump(list(pr_lookup.values()), f, indent=2)\n",
    "            current_batch = []\n",
    "\n",
    "    # Save any remaining PRs\n",
    "    if current_batch:\n",
    "        print(f\"Saving final batch of {len(current_batch)} newly classified PRs...\")\n",
    "        with open(enriched_file, 'w') as f:\n",
    "            json.dump(list(pr_lookup.values()), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = PRClassifier(pipeline)\n",
    "repo_name = \"nosara\"\n",
    "#repo_name = \"looker\"\n",
    "update_confidentiality_status(repo_name, classifier, batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
